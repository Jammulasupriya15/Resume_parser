{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\programdata\\anaconda3\\lib\\site-packages (1.22.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import spacy\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/',\n",
       " {'entities': [(1749, 1755, 'Companies worked at'),\n",
       "   (1696, 1702, 'Companies worked at'),\n",
       "   (1417, 1423, 'Companies worked at'),\n",
       "   (1356, 1793, 'Skills'),\n",
       "   (1209, 1215, 'Companies worked at'),\n",
       "   (1136, 1248, 'Skills'),\n",
       "   (928, 932, 'Graduation Year'),\n",
       "   (858, 889, 'College Name'),\n",
       "   (821, 856, 'Degree'),\n",
       "   (787, 791, 'Graduation Year'),\n",
       "   (744, 750, 'Companies worked at'),\n",
       "   (722, 742, 'Designation'),\n",
       "   (658, 664, 'Companies worked at'),\n",
       "   (640, 656, 'Designation'),\n",
       "   (574, 580, 'Companies worked at'),\n",
       "   (555, 573, 'Designation'),\n",
       "   (470, 493, 'Companies worked at'),\n",
       "   (444, 469, 'Designation'),\n",
       "   (308, 314, 'Companies worked at'),\n",
       "   (234, 240, 'Companies worked at'),\n",
       "   (175, 198, 'Companies worked at'),\n",
       "   (93, 137, 'Email Address'),\n",
       "   (39, 48, 'Location'),\n",
       "   (13, 38, 'Designation'),\n",
       "   (0, 12, 'Name')]})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pickle.load(open('C:/Users/Jammula/Dropbox/My PC (DESKTOP-L6TP5LR)/Downloads/train_data.pkl','rb'))\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'ner': 6557.774650334544}\n",
      "Starting iteration 1\n",
      "{'ner': 5007.9488951202375}\n",
      "Starting iteration 2\n",
      "{'ner': 3370.6866396523187}\n",
      "Starting iteration 3\n",
      "{'ner': 2274.7622784011974}\n",
      "Starting iteration 4\n",
      "{'ner': 1959.4003404131697}\n",
      "Starting iteration 5\n",
      "{'ner': 1664.8170743299}\n",
      "Starting iteration 6\n",
      "{'ner': 1507.3658946846301}\n",
      "Starting iteration 7\n",
      "{'ner': 1350.762043952893}\n",
      "Starting iteration 8\n",
      "{'ner': 1329.479956083972}\n",
      "Starting iteration 9\n",
      "{'ner': 1266.870524961845}\n"
     ]
    }
   ],
   "source": [
    "# Load Blank Model\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "def train_model(train_data):\n",
    "    # Remove all pipelines and add NER pipeline from the model\n",
    "    if 'ner'not in nlp.pipe_names:\n",
    "       \n",
    "        # adding NER pipeline to nlp model\n",
    "        ner = nlp.add_pipe('ner',last=True)\n",
    "    \n",
    "    #Add labels in the NLP pipeline\n",
    "    for _, annotation in train_data:\n",
    "        for ent in annotation.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "    \n",
    "    #Remove other pipelines if they are there\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(10): # train for 10 iterations\n",
    "            print(\"Starting iteration \" + str(itn))\n",
    "            random.shuffle(train_data)\n",
    "            losses = {}\n",
    "            index = 0\n",
    "            for text, annotations in train_data:\n",
    "                try:\n",
    "                    \n",
    "                    doc = nlp.make_doc(text)\n",
    "                    biluo_tags = spacy.training.offsets_to_biluo_tags(doc, annotations.get('entities'))\n",
    "                    # Create an Example object from the doc and annotations\n",
    "                    example = spacy.training.example.Example.from_dict(doc, {'entities': biluo_tags})\n",
    "                    nlp.update(\n",
    "                        [example],  # batch of texts\n",
    "                          # batch of annotations\n",
    "                        drop=0.2,  # dropout - make it harder to memorise data\n",
    "                        sgd=optimizer,  # callable to update weights\n",
    "                        losses=losses)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "            print(losses)\n",
    "# Start Training model\n",
    "train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk('nlp_ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loading Model\n",
    "nlp_model = spacy.load('nlp_ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          -Vamsi krishna\n",
      "LOCATION                      -hyderbad\n",
      "DESIGNATION                   -Software developer\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "DEGREE                        -Bsc\n",
      "COLLEGE NAME                  -Shri gnanambika degree college\n",
      "SKILLS                        -Analytics, Research\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_model(train_data[0][0])\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.label_.upper():{30}}-{ent.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in c:\\programdata\\anaconda3\\lib\\site-packages (1.22.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMuPDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice Clark  AI / Machine Learning    Delhi, India Email me on Indeed  •  20+ years of experience in data handling, design, and development  •  Data Warehouse: Data analysis, star/snow flake scema data modelling and design specific to  data warehousing and business intelligence  •  Database: Experience in database designing, scalability, back-up and recovery, writing and  optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.  Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure,  Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake  analytics(U-SQL)  Willing to relocate anywhere    WORK EXPERIENCE  Software Engineer  Microsoft – Bangalore, Karnataka  January 2000 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping  online. Microsoft Rewards members can earn points when searching with Bing, browsing with  Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft  Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft  rewards website. Rewards live dashboards gives a live picture of usage world-wide and by  markets like US, Canada, Australia, new user registration count, top/bottom performing rewards  offers, orders stats and weekly trends of user activities, orders and new user registrations. the  PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.  Technology/Tools used    EDUCATION  Indian Institute of Technology – Mumbai  2001    SKILLS  Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills  • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal  skills with ability to interact with individuals at all the levels  • Quick learner and maintains cordial relationship with project manager and team members and  good performer both in team and independent job environments  • Positive attitude towards superiors &amp; peers  • Supervised junior developers throughout project lifecycle and provided technical assistance  \n"
     ]
    }
   ],
   "source": [
    "import sys, fitz\n",
    "fname = '\"C:/Users/Jammula/Dropbox/My PC (DESKTOP-L6TP5LR)/Downloads/Research Parse Resume.pdf\"'\n",
    "doc = fitz.open(fname)\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text = text + str(page.get_text()) \n",
    "tx = \" \".join(text.split('\\n'))\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          -Alice Clark\n",
      "LOCATION                      -Delhi\n",
      "DESIGNATION                   -Software Engineer\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "COMPANIES WORKED AT           -Microsoft\n",
      "LOCATION                      -Store\n",
      "COLLEGE NAME                  -Indian Institute of Technology\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_model(tx)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.label_.upper():{30}}-{ent.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
